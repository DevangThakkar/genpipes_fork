[default]
clusterSubmitCmd=qsub
clusterSubmitCmdSuffix= | grep \"[0-9]\"
clusterWalltime=-l walltime=24:00:0
clusterCPU=-l nodes=1:ppn=1
clusterOtherArg=-V -m ae -M $JOB_MAIL -W umask=0002
clusterQueue=-q sw
clusterWorkDirArg=-d
clusterOutputDirArg=-j oe -o
clusterJobNameArg=-N
clusterCmdProducesJobId=true
clusterDependencyArg=-W depend=afterok:
clusterDependencySep=:
referenceFasta=/software/areas/genomics/genomes/Homo_sapiens/hg19/fasta/hg19.fasta
referenceSequenceDictionary=/software/areas/genomics/genomes/Homo_sapiens/hg19/fasta/hg19.fasta.dict
referenceMappabilityBedIndexed=/software/areas/genomics/genomes/Homo_sapiens/hg19/annotations/mappabilityGC/Illu_PE.exclusion.bed.gz
specieVcfFormatDescriptor=/software/areas/genomics/phase2/genomes/Homo_sapiens/hg1k_v37/annotations/HumanVCFformatDescriptor.tsv
referenceSnpEffGenome=hg19
igvGenome=hg19
dbSnp=/software/areas/genomics/genomes/Homo_sapiens/hg19/annotations/dbsnp137.hg19.vcf
knownSites=/software/areas/genomics/genomes/Homo_sapiens/hg19/annotations/dbsnp137.hg19.vcf.gz
dbNSFP=/software/areas/genomics/genomes/Homo_sapiens/hg1k_v37/annotations/dbNSFP2.0/dbNSFP2.0.txt
commonSNPPos=/software/areas/genomics/genomes/Homo_sapiens/hg1k_v37/annotations/common.dbsnp132.q60.tsv
extraJavaFlags=-XX:ParallelGCThreads=1 -Dsamjdk.use_async_io=true -Dsamjdk.buffer_size=4194304
tmpDir=/localscratch/
rawReadDir=raw_reads

## sould be experimentType="wholeGenome" for WGS metrics
experimentType="wholeGenome"
## prefix identifier for job  
projectName="DNAseq"

moduleVersion.trimmomatic=mugqic/trimmomatic/0.30
moduleVersion.bwa=mugqic/bwa/0.7.7
moduleVersion.bvatools=mugqic/bvatools/1.3
moduleVersion.java=mugqic/java/openjdk-jdk1.7.0_60
moduleVersion.picard=mugqic/picard/1.118
moduleVersion.samtools=mugqic/samtools/0.1.19-gpfs
moduleVersion.gatk=mugqic/GenomeAnalysisTK/3.1-1
moduleVersion.igvtools=mugqic/igvtools/2.3.14
moduleVersion.vcftools=mugqic/vcftools/0.1.11
moduleVersion.tabix=mugqic/tabix/0.2.6
moduleVersion.snpeff=mugqic/snpEff/3.4
moduleVersion.tools=mugqic/tools/1.9
moduleVersion.cranR=mugqic/R/3.0.2
moduleVersion.python=mugqic/python/2.7.6
moduleVersion.perl=mugqic/perl/5.18.2

[samToFastq]
extraJavaFlags=-XX:ParallelGCThreads=1 -Dsamjdk.use_async_io=true -Dsamjdk.buffer_size=4194304
samToFastqRam=10G
clusterCPU=-l nodes=1:ppn=3

[trim]
# Don't do trimming of any kind
#skip=1
nbThreads=6
minQuality=30
minLength=50
adapterFile=$MUGQIC_INSTALL_HOME/software/mugqic_pipeline/v1.3/lib/adapters-truseq.fa
clipSettings=:2:30:15
# To keep overlapping pairs use the following
# clipSettings=:2:30:15:8:true

clusterWalltime=-l walltime=24:00:0
clusterCPU=-l nodes=1:ppn=6

[aln]
# aligner can be 'mem' or 'backtrack'
# for mem, a 'mem' section is needed
# for 'backtrack' uncomment this section
aligner=mem
#bwaAlnThreads=12
#bwaExtraSamXeFlags=-T -t 11
#bwaRefIndex=/software/areas/genomics/genomes/Homo_sapiens/hg19/fasta/bwa/hg19.fasta
#bwaInstitution=McGill University and Genome Quebec Innovation Center
#sortRam=15G
#sortRecInRam=3750000
#clusterWalltime=-l walltime=24:00:0
#clusterCPU=-l nodes=1:ppn=12

[mem]
bwaExtraFlags=-M -t 7
bwaRefIndex=/software/areas/genomics/genomes/Homo_sapiens/hg19/fasta/bwa/hg19.fasta
bwaInstitution=McGill University and Genome Quebec Innovation Center
sortRam=15G
sortRecInRam=3750000
clusterWalltime=-l walltime=24:00:0
clusterCPU=-l nodes=1:ppn=8

[mergeFiles]
mergeRam=1700M
mergeRecInRam=250000

[mergeLanes]
clusterWalltime=-l walltime=35:00:0
clusterCPU=-l nodes=1:ppn=2

[indelRealigner]
realignRam=3200M
realignReadsInRam=500000
indelRealignerExtraFlags="" 
targetCreatorExtraFlags=""
nbRealignJobs=3
clusterWalltime=-l walltime=35:00:0
clusterCPU=-l nodes=1:ppn=2

[mergeRealign]
clusterWalltime=-l walltime=35:00:0
clusterCPU=-l nodes=1:ppn=2

[fixmate]
ram=10G
extraSortFlags=-@ 3 -m 5000M
clusterWalltime=-l walltime=35:00:0
clusterCPU=-l nodes=1:ppn=12

[markDup]
markDupRam=5G
markDupRecInRam=1000000
clusterWalltime=-l walltime=48:00:0
clusterCPU=-l nodes=1:ppn=2

[recalibration]
threads=5
recalRam=11G
clusterWalltime=-l walltime=72:00:0
clusterCPU=-l nodes=1:ppn=6

[collectMetrics]
collectMetricsRam=3G
collectMetricsRecInRam=1000000
clusterWalltime=-l walltime=48:00:0
clusterCPU=-l nodes=1:ppn=2

[calculateHSMetrics]
ram=4G
clusterWalltime=-l walltime=24:00:0
clusterCPU=-l nodes=1:ppn=2

[depthOfCoverage]
# you can set it implicitly, leave blank for whole genome or set auto which uses the sampleSheet to identify the bed file.
coverageTargets=auto
# maxDepth is RAM limited. maxDepth * 8 * nbIntervals ~= RAM needed
extraFlags="--gc --maxDepth 1001 --summaryCoverageThresholds 10,25,50,75,100,500,1000 --minMappingQuality 15 --minBaseQuality 15 --ommitN --threads 3"
ram=7G
clusterWalltime=-l walltime=48:00:0
clusterCPU=-l nodes=1:ppn=4

[genomeCoverage]
genomeCoverageRam=6G
percentThresholds=10,25,50,75,100,500
extraJavaFlags=-XX:ParallelGCThreads=2
clusterWalltime=-l walltime=96:00:0
clusterCPU=-l nodes=1:ppn=3

[targetCoverage]
coverageRam=6G
percentThresholds=10,25,50,75,100,500
extraJavaFlags=-XX:ParallelGCThreads=2
coverageTargets=/software/areas/genomics/genomes/Homo_sapiens/hg19/annotations/CCDS.hg19.bed
clusterWalltime=-l walltime=96:00:0
clusterCPU=-l nodes=1:ppn=3

[computeTDF]
clusterWalltime=-l walltime=48:00:0
clusterCPU=-l nodes=1:ppn=2

[callableBases]
ram=1G
# Usually you should put minDepthForLowMAPQ >= minDepth
extraFlags=-dt none --minDepth 10 --maxDepth 500 --minDepthForLowMAPQ 10 --minMappingQuality 10 --minBaseQuality 15
clusterCPU=-l nodes=1:ppn=2

[basefreq]
# Don't use the index, parse the whole file. Less RAM is needed this way
threads=0
ram=7G

[extractCommonSNPFreq]
clusterWalltime=-l walltime=24:00:0
clusterCPU=-l nodes=1:ppn=5

[bafPlot]
ram=70G
extraFlags="--plot --maxDepth 1000  --exclude MT,GL000207.1,GL000226.1,GL000229.1,GL000231.1,GL000210.1,GL000239.1,GL000235.1,GL000201.1,GL000247.1,GL000245.1,GL000197.1,GL000203.1,GL000246.1,GL000249.1,GL000196.1,GL000248.1,GL000244.1,GL000238.1,GL000202.1,GL000234.1,GL000232.1,GL000206.1,GL000240.1,GL000236.1,GL000241.1,GL000243.1,GL000242.1,GL000230.1,GL000237.1,GL000233.1,GL000204.1,GL000198.1,GL000208.1,GL000191.1,GL000227.1,GL000228.1,GL000214.1,GL000221.1,GL000209.1,GL000218.1,GL000220.1,GL000213.1,GL000211.1,GL000199.1,GL000217.1,GL000216.1,GL000215.1,GL000205.1,GL000219.1,GL000224.1,GL000223.1,GL000195.1,GL000212.1,GL000222.1,GL000200.1,GL000193.1,GL000194.1,GL000225.1,GL000192.1"

[BAFPlot]
clusterWalltime=-l walltime=24:00:0
clusterQueue=-q lm
clusterCPU=-l nodes=1:ppn=12

[haplotypeCaller]
# first option is ONLY for sandybridge
#options=--pair_hmm_implementation VECTOR_LOGLESS_CACHING --emitRefConfidence GVCF --variant_index_type LINEAR --variant_index_parameter 128000 -dt none -nct 15
options=--emitRefConfidence GVCF --variant_index_type LINEAR --variant_index_parameter 128000 -dt none -nct 15
ram=55G
# Max is 1 per chromosome
nbJobs=4
clusterWalltime=-l walltime=35:00:0
clusterCPU=-l nodes=1:ppn=16

[mergeAndCallGVCF]
catOptions=""
callOptions=-nt 3
ram=6G
clusterWalltime=-l walltime=24:00:0
clusterCPU=-l nodes=1:ppn=3

[mpileup]
mpileupExtraFlags=-L 1000 -E -q 1 -D -S -g -u
approxNbJobs=300
clusterWalltime=-l walltime=48:00:0
clusterCPU=-l nodes=1:ppn=3

[mergeFilterBCF]
clusterWalltime=-l walltime=24:00:0
clusterCPU=-l nodes=1:ppn=1

[rawmpileup]
mpileupExtraFlags=-d 1000 -B -q 1 -Q 0
clusterWalltime=-l walltime=96:00:0
clusterCPU=-l nodes=1:ppn=2

[annotateDbSnp]
siftRam=8G
extraJavaFlags=-XX:ParallelGCThreads=2
clusterCPU=-l nodes=1:ppn=2

[annotateDbNSFP]
siftRam=8G
extraJavaFlags=-XX:ParallelGCThreads=2
clusterCPU=-l nodes=1:ppn=2

[computeEffects]
extraJavaFlags=-XX:ParallelGCThreads=1
snpeffRam=2G
#snpeffParams=
#referenceSnpEffGenome=

[sortQname]

[countTelomere]

[fullPileup]
